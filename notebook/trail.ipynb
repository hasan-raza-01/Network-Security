{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/hasan/Documents/DS/Udemy/ML-Project-with-ETL-Pipeline/materials/networksecurity/Network_Data/phisingData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"schema\"\n",
    "os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dict()\n",
    "columns_with_dtype = dict()\n",
    "numerical_columns = list()\n",
    "for col in data.columns:\n",
    "    columns_with_dtype[col] = str(data[col].dtype)\n",
    "    if data[col].dtype!=\"O\":\n",
    "        numerical_columns.append(col)\n",
    "schema[\"columns\"] = columns_with_dtype\n",
    "schema[\"numerical_columns\"] = numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(schema['columns'].keys()))\n",
    "print(len(data.columns))\n",
    "len(schema['columns'].keys()) == len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema[\"numerical_columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, \"schema.yaml\"), \"w\") as file:\n",
    "    yaml.safe_dump(schema, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, \"schema.yaml\"),) as file:\n",
    "    content = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[\"columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[\"numerical_columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Data to be written\n",
    "dictionary = {\n",
    "\t\"name\": \"sathiyajith\",\n",
    "\t\"rollno\": 56,\n",
    "\t\"cgpa\": 8.6,\n",
    "\t\"phonenumber\": \"9976770500\"\n",
    "}\n",
    "\n",
    "# Serializing json\n",
    "json_object = json.dumps(dictionary, indent=4)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "\toutfile.write(json_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Opening JSON file\n",
    "with open('sample.json', 'r') as openfile:\n",
    "\n",
    "\t# Reading from json file\n",
    "\tjson_object = json.load(openfile)\n",
    "\n",
    "print(json_object)\n",
    "print(type(json_object))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "value = json.dumps({\"max_features\":[\"sqrt\",\"log2\",None]})\n",
    "print(value)\n",
    "\n",
    "loaded_value = json.loads(value)\n",
    "print(loaded_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.utils import load_json\n",
    "\n",
    "load_json(\"params.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv.version\n",
    "import mlflow, dagshub, dvc, bentoml, dotenv, box, ipykernel, pymongo, sklearn, fastapi, flask\n",
    "\n",
    "print(f\"mlflow=={mlflow.__version__}\")\n",
    "print(f\"dagshub=={dagshub.__version__}\")\n",
    "print(f\"dvc=={dvc.__version__}\")\n",
    "print(f\"bentoml=={bentoml.__version__}\")\n",
    "print(f\"python-dotenv=={dotenv.version.__version__}\")\n",
    "print(f\"python-box=={box.__version__}\")\n",
    "print(f\"ipykernel=={ipykernel.__version__}\")\n",
    "print(f\"pymongo=={pymongo.__version__}\")\n",
    "print(f\"scikit-learn=={sklearn.__version__}\")\n",
    "print(f\"fastapi=={fastapi.__version__}\")\n",
    "print(f\"flask=={flask.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='hasan-raza-01', repo_name='Network-Security', mlflow=True)\n",
    "model_uri = 'runs:/6f9dc37926ad48d2b713e425d3fb1991/RandomForestClassifier'\n",
    "model = bentoml.mlflow.import_model(\"RandomForestClassifier\", model_uri).load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict on a Pandas DataFrame.\n",
    "data = np.load(\"artifacts/data/transformation/test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import numpy\n",
    "# numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(data[:, -1])[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[55, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[55, :-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"test_application\"\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "np.save(f\"{dir_name}/X_test_1.npy\", [data[55, :-1]])\n",
    "np.save(f\"{dir_name}/X_test_2.npy\", data[0:3, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dir_name = \"test_application\"\n",
    "arr=np.load(f\"{dir_name}/X_test_1d_array.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(arr)\n",
    "df = df.drop(df.columns[-1], axis=1)\n",
    "input_data = np.array(df[df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.shape, input_data.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[55, :-1].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:3, :-1].shape, data[0:3, :-1].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:3, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:3, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:3, :-1].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(data[0, :-1].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1094, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1094, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1094, -1], model.predict(data[1094, :-1].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as Numpy\n",
    "from package.pipeline.prediction_pipeline import PredictionPipeline\n",
    "from package.configuration import DataTransformationConfig, ModelTrainerConfig\n",
    "from package.utils import load_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_obj(ModelTrainerConfig.ESTIMATOR_FILE_PATH)\n",
    "preprocessor = load_obj(DataTransformationConfig.PREPROCESSOR_PATH)\n",
    "pipeline = PredictionPipeline(model, preprocessor, data=Numpy.array([\n",
    "        [-1, -1,  1,  1,  1, -1, -1,  0, -1,  1,  1,  1, -1, -1, -1, -1,  1, 1,  0,  1,  1,  1,  1,  1,  1,  0, -1,  1,  1,  1]\n",
    "]))\n",
    "pred = pipeline.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(output=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.utils import load_obj\n",
    "from package.configuration import ModelTrainerConfig\n",
    "model = load_obj(ModelTrainerConfig.ESTIMATOR_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
